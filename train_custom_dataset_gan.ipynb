{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using NVIDIA's Stylegan2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Setting the environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's first install the libraries which GAN uses to do the generation and training. As of now, it requires `torch 1.8.x` to run and most importantly, `ninja`\n",
    "\n",
    "For further reference, this notebook took help from the following sources:\n",
    "\n",
    "https://www.youtube.com/watch?v=L3JLzoe-dJU\n",
    "\n",
    "and https://github.com/jeffheaton/present/blob/master/youtube/gan/colab_gan_train.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch==1.8.1 torchvision==0.9.1\n",
    "!pip install ninja"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we'll get the latest repo of GAN to use the GAN code. This is **NVIDIA's** product and is avaialble in **NVlabs** github account."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/NVlabs/stylegan2-ada-pytorch.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NExt, just out of curiosity, we'll check what GPU we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Mar  1 16:16:49 2022       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 511.79       Driver Version: 511.79       CUDA Version: 11.6     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name            TCC/WDDM | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ... WDDM  | 00000000:01:00.0 Off |                  N/A |\n",
      "| N/A   58C    P8     5W /  N/A |      0MiB /  6144MiB |      0%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A     57724    C+G   ...n64\\EpicGamesLauncher.exe    N/A      |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Getting and processing the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now for the dataset, first we would need to convert all the images into the dimensions which are multiple of 2 like 256x256 px, 512x512 px, 1024x1024 px etc. In this case 512x512 px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "path = \"D:\\Dataset\\SKU110K_fixed\\more_blank\\\\\"\n",
    "dest_path = \"D:\\Dataset\\SKU110K_fixed\\more_blank_512\\\\\"\n",
    "dirs = os.listdir(path)\n",
    "\n",
    "def resize():\n",
    "    for item in dirs:\n",
    "        if item == '.jpg':\n",
    "            continue\n",
    "        if os.path.isfile(path+item):\n",
    "            image = Image.open(path+item)\n",
    "            file_path, extension = os.path.splitext(path+item)\n",
    "            size = image.size\n",
    "\n",
    "            new_image_height = 512\n",
    "            new_image_width = 512\n",
    "\n",
    "            try:\n",
    "              if not os.path.isfile(dest_path + item):\n",
    "                print(dest_path + item)\n",
    "                image = image.resize((new_image_height, new_image_width), Image.ANTIALIAS)\n",
    "                image.save(dest_path + item, 'JPEG', quality=90)\n",
    "            except Exception as e:\n",
    "              print(\"Corrupted File : \",e)\n",
    "              \n",
    "\n",
    "\n",
    "resize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once done, we would create the dataset from it using the code from the NVlab's repo we just cloned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "stylegan2_git_repo = 'D:\\Git_Repositories\\stylegan2-ada-pytorch\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/55 [00:00<?, ?it/s]\n",
      " 13%|█▎        | 7/55 [00:00<00:00, 70.00it/s]\n",
      " 27%|██▋       | 15/55 [00:00<00:00, 71.75it/s]\n",
      " 42%|████▏     | 23/55 [00:00<00:00, 73.62it/s]\n",
      " 56%|█████▋    | 31/55 [00:00<00:00, 75.21it/s]\n",
      " 71%|███████   | 39/55 [00:00<00:00, 74.25it/s]\n",
      " 84%|████████▎ | 46/55 [00:00<00:00, 72.92it/s]\n",
      " 98%|█████████▊| 54/55 [00:00<00:00, 72.67it/s]\n",
      "100%|██████████| 55/55 [00:00<00:00, 74.02it/s]\n"
     ]
    }
   ],
   "source": [
    "!python D:/Git_Repositories/stylegan2-ada-pytorch/dataset_tool.py --source D:/Dataset/SKU110K_fixed/more_blank_512/ --dest D:/Dataset/SKU110K_fixed/more_blank_512_dataset/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Starting Training GAN on new Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "# Modify these to suit your needs\n",
    "EXPERIMENTS = \"D:/Dataset/SKU110K_fixed/more_blank_Experiments/\"\n",
    "DATA = \"D:/Dataset/SKU110K_fixed/more_blank_512_dataset/\"\n",
    "SNAP = 2\n",
    "\n",
    "# Build the command and run it\n",
    "cmd = f\"python D:/Git_Repositories/stylegan2-ada-pytorch/train.py --snap {SNAP} --outdir {EXPERIMENTS} --data {DATA}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are chances the the training might stop in between, and we should restart the training from where it stopped. So for that, here's what we have to do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Modify these to suit your needs\n",
    "EXPERIMENTS = \"D:/Dataset/SKU110K_fixed/SKU110K_fixed/Experiments\"\n",
    "NETWORK = \"network-snapshot-000040.pkl\"\n",
    "RESUME = os.path.join(EXPERIMENTS, \"00002-dataset-auto1\", NETWORK)\n",
    "DATA = \"D:/Dataset/SKU110K_fixed/SKU110K_fixed/dataset/\"\n",
    "SNAP = 2\n",
    "\n",
    "# Build the command and run it\n",
    "cmd = f\"python D:/Git_Repositories/stylegan2-ada-pytorch/train.py --snap {SNAP} --resume {RESUME} --outdir {EXPERIMENTS} --data {DATA}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Generating new data\n",
    "\n",
    "We've successfully trained the GANs for sufficient amount of epochs (Kimgs) and now we're ready to generate the new data from it.\n",
    "\n",
    "Notice here: `--seeds` could be any random number, `1-2000` means it'll generate two thousands different images it could also be `1-8000` or any random number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "\n",
    "# The location of the final pkl file.\n",
    "NETWORK = \"D:/Dataset/SKU110K_fixed/SKU110K_fixed/Experiments/00009-dataset-auto1-resumecustom/network-snapshot-000064.pkl\"\n",
    "\n",
    "# Output folder\n",
    "OUT = \"D:/Dataset/SKU110K_fixed/SKU110K_fixed/generated_images\"\n",
    "TRUNC = 1\n",
    "\n",
    "# command to generate images\n",
    "cmd = f\"python3 D:/Git_Repositories/stylegan2-ada-pytorch/generate.py --outdir {OUT} --trunc {TRUNC} --seeds 1-2000 --network {NETWORK}\"\n",
    "!{cmd}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "fe1fbfa14f7916735696a9322e667a237902258ca1fb6b99eeb22f79e9159140"
  },
  "kernelspec": {
   "display_name": "Python 3.8.6 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
